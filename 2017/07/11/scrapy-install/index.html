<!DOCTYPE html>
<html lang="zh-Hans">
<head>

    <!--[if lt IE 9]>
        <style>body {display: none; background: none !important} </style>
        <meta http-equiv="Refresh" Content="0; url=//outdatedbrowser.com/" />
    <![endif]-->

<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<meta name="format-detection" content="telephone=no" />
<meta name="author" content="一条大河" />



<meta name="description" content="摘要：记录一下scrapy的安装过程，尤其是在windows上的安装会遇到一些问题">
<meta property="og:type" content="article">
<meta property="og:title" content="Python爬虫框架scrapy的安装">
<meta property="og:url" content="http://riverdba.github.io/2017/07/11/scrapy-install/index.html">
<meta property="og:site_name" content="Yangtze River's blog">
<meta property="og:description" content="摘要：记录一下scrapy的安装过程，尤其是在windows上的安装会遇到一些问题">
<meta property="og:updated_time" content="2017-07-11T02:40:00.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Python爬虫框架scrapy的安装">
<meta name="twitter:description" content="摘要：记录一下scrapy的安装过程，尤其是在windows上的安装会遇到一些问题">

<link rel="apple-touch-icon" href= "/apple-touch-icon.png">


    <link rel="alternate" href="/atom.xml" title="Yangtze River&#39;s blog" type="application/atom+xml">



    <link rel="shortcut icon" href="/yangtzeriver.jpg">



    <link href="//cdn.bootcss.com/animate.css/3.5.1/animate.min.css" rel="stylesheet">



    <link href="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.css" rel="stylesheet">



    <script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script>
    <link href="//cdn.bootcss.com/pace/1.0.2/themes/blue/pace-theme-minimal.css" rel="stylesheet">


<link rel="stylesheet" href="/css/style.css">



<link href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">


<title>Python爬虫框架scrapy的安装 | Yangtze River&#39;s blog</title>

<script src="//cdn.bootcss.com/jquery/2.2.4/jquery.min.js"></script>
<script src="//cdn.bootcss.com/clipboard.js/1.5.10/clipboard.min.js"></script>

<script>
    var yiliaConfig = {
        fancybox: true,
        animate: true,
        isHome: false,
        isPost: true,
        isArchive: false,
        isTag: false,
        isCategory: false,
        fancybox_js: "//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.js",
        scrollreveal: "//cdn.bootcss.com/scrollReveal.js/3.1.4/scrollreveal.min.js",
        search: true
    }
</script>


    <script>
        yiliaConfig.jquery_ui = [true, "//cdn.bootcss.com/jqueryui/1.10.4/jquery-ui.min.js", "//cdn.bootcss.com/jqueryui/1.10.4/css/jquery-ui.min.css"];
    </script>



    <script> yiliaConfig.rootUrl = "\/";</script>






</head>
<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
    <header id="header" class="inner">
        <a href="/" class="profilepic">
            <img src="/img/yangtzeriver.jpg" class="animated zoomIn">
        </a>
        <hgroup>
          <h1 class="header-author"><a href="/">一条大河</a></h1>
        </hgroup>

        
        <p class="header-subtitle">为学患无疑，疑则进也！</p>
        

        
            <form id="search-form">
            <input type="text" id="local-search-input" name="q" placeholder="search..." class="search form-control" autocomplete="off" autocorrect="off" searchonload="false" />
            <i class="fa fa-times" onclick="resetSearch()"></i>
            </form>
            <div id="local-search-result"></div>
            <p class='no-result'>No results found <i class='fa fa-spinner fa-pulse'></i></p>
        


        
            <div id="switch-btn" class="switch-btn">
                <div class="icon">
                    <div class="icon-ctn">
                        <div class="icon-wrap icon-house" data-idx="0">
                            <div class="birdhouse"></div>
                            <div class="birdhouse_holes"></div>
                        </div>
                        <div class="icon-wrap icon-ribbon hide" data-idx="1">
                            <div class="ribbon"></div>
                        </div>
                        
                        <div class="icon-wrap icon-link hide" data-idx="2">
                            <div class="loopback_l"></div>
                            <div class="loopback_r"></div>
                        </div>
                        
                        
                    </div>
                    
                </div>
                <div class="tips-box hide">
                    <div class="tips-arrow"></div>
                    <ul class="tips-inner">
                        <li>菜单</li>
                        <li>标签</li>
                        
                        <li>友情链接</li>
                        
                        
                    </ul>
                </div>
            </div>
        

        <div id="switch-area" class="switch-area">
            <div class="switch-wrap">
                <section class="switch-part switch-part1">
                    <nav class="header-menu">
                        <ul>
                        
                            <li><a href="/">主页</a></li>
                        
                            <li><a href="/archives/">所有文章</a></li>
                        
                            <li><a href="/tags/">标签云</a></li>
                        
                            <li><a href="/about/">关于我</a></li>
                        
                        </ul>
                    </nav>
                    <nav class="header-nav">
                        <ul class="social">
                            
                                <a class="fa Email" href="mailto:river_dba@foxmail.com" title="Email"></a>
                            
                                <a class="fa GitHub" href="#" title="GitHub"></a>
                            
                                <a class="fa RSS" href="/atom.xml" title="RSS"></a>
                            
                        </ul>
                    </nav>
                </section>
                
                
                <section class="switch-part switch-part2">
                    <div class="widget tagcloud" id="js-tagcloud">
                        <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/GDB/">GDB</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hexo-Quick-Start/">Hexo Quick Start</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MySQL性能调优技术/">MySQL性能调优技术</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MySQL查询优化技术/">MySQL查询优化技术</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python-pt-kill/">Python+pt-kill</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SQL审核工具/">SQL审核工具</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/disqus/">disqus</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/online-ddl/">online ddl</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/scrapy/">scrapy</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/sqlite3/">sqlite3</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/sysbench/">sysbench</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/学习笔记/">学习笔记</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/工作笔记/">工作笔记</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/故障诊断/">故障诊断</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/数据库恢复/">数据库恢复</a></li></ul>
                    </div>
                </section>
                
                
                
                <section class="switch-part switch-part3">
                    <div id="js-friends">
                    
                      <a class="main-nav-link switch-friends-link" href="https://hexo.io">Hexo</a>
                    
                      <a class="main-nav-link switch-friends-link" href="https://pages.github.com/">GitHub</a>
                    
                      <a class="main-nav-link switch-friends-link" href="http://moxfive.xyz/">MOxFIVE</a>
                    
                      <a class="main-nav-link switch-friends-link" href="http://moxfive.xyz/yelee/">yelee主题</a>
                    
                      <a class="main-nav-link switch-friends-link" href="https://dbanote.github.io">刘雅君</a>
                    
                    </div>
                </section>
                

                
            </div>
        </div>
    </header>                
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
      <div class="overlay">
          <div class="slider-trigger"></div>
          <h1 class="header-author js-mobile-header hide"><a href="/" title="回到主页">一条大河</a></h1>
      </div>
    <div class="intrude-less">
        <header id="header" class="inner">
            <a href="/" class="profilepic">
                <img src="/img/yangtzeriver.jpg" class="animated zoomIn">
            </a>
            <hgroup>
              <h1 class="header-author"><a href="/" title="回到主页">一条大河</a></h1>
            </hgroup>
            
            <p class="header-subtitle">为学患无疑，疑则进也！</p>
            
            <nav class="header-menu">
                <ul>
                
                    <li><a href="/">主页</a></li>
                
                    <li><a href="/archives/">所有文章</a></li>
                
                    <li><a href="/tags/">标签云</a></li>
                
                    <li><a href="/about/">关于我</a></li>
                
                <div class="clearfix"></div>
                </ul>
            </nav>
            <nav class="header-nav">
                        <ul class="social">
                            
                                <a class="fa Email" target="_blank" href="mailto:river_dba@foxmail.com" title="Email"></a>
                            
                                <a class="fa GitHub" target="_blank" href="#" title="GitHub"></a>
                            
                                <a class="fa RSS" target="_blank" href="/atom.xml" title="RSS"></a>
                            
                        </ul>
            </nav>
        </header>                
    </div>
    <link class="menu-list" tags="标签" friends="友情链接" about="关于我"/>
</nav>
      <div class="body-wrap"><article id="post-scrapy-install" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2017/07/11/scrapy-install/" class="article-date">
      <time datetime="2017-07-11T01:55:42.000Z" itemprop="datePublished">2017-07-11</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Python爬虫框架scrapy的安装
    </h1>
  

      </header>
      
      <div class="article-info article-info-post">
        
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/Python/">Python</a>
    </div>


        
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/scrapy/">scrapy</a></li></ul>
    </div>

        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <p><excerpt in="" index="" |="" 首页摘要=""><br>摘要：记录一下scrapy的安装过程，尤其是在windows上的安装会遇到一些问题<a id="more"></a></excerpt></p>
<the rest="" of="" contents="" |="" 余下全文="">

<h2 id="Linux上安装Scrapy"><a href="#Linux上安装Scrapy" class="headerlink" title="Linux上安装Scrapy"></a>Linux上安装Scrapy</h2><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>直接使用pip install scrapy访问国外的源会经常超时，因此建议使用国内的站点快速安装：<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">[root@mysql .pip]# pip install scrapy -i https://pypi.tuna.tsinghua.edu.cn/simple</div><div class="line">Collecting scrapy</div><div class="line">  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/a8/96/3affe11cf53a5d2105536919113d5b453479038bb486f7387f4ce4a3b83f/Scrapy-1.4.0-py2.py3-none-any.whl (248kB)</div><div class="line">    100% |████████████████████████████████| 256kB 2.0MB/s </div><div class="line">Collecting queuelib (from scrapy)</div><div class="line">  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/16/4f/b307fc978a21bfbb138e8e01a9f4953191d439e30578f5e4fd5befa77de1/queuelib-1.4.2-py2.py3-none-any.whl</div><div class="line">Collecting w3lib&gt;=1.17.0 (from scrapy)</div><div class="line">  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/20/3e/ba9865b88c39edd09100a8c8df11722c8881bbf76aef0c0ae5b970eb42b7/w3lib-1.17.0-py2.py3-none-any.whl</div><div class="line">Collecting cssselect&gt;=0.9 (from scrapy)</div><div class="line">  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/1d/e5/f1d410192e34b1034dba7804de5dbcdece20a883c445ad661e5ea8226b42/cssselect-1.0.1-py2.py3-none-any.whl</div><div class="line">Collecting lxml (from scrapy)</div><div class="line">  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/62/b7/aafdcf0c0ad0cf36a0835adde50f4a7e18241440b9897a88c80f520d0c76/lxml-3.8.0-cp27-cp27m-manylinux1_x86_64.whl (6.8MB)</div><div class="line">    100% |████████████████████████████████| 6.8MB 193kB/s </div><div class="line">Collecting parsel&gt;=1.1 (from scrapy)</div><div class="line">  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/d0/bd/c5c3cf9c490d328a1d1e5e942c3a2b84d6934d5666e9d4bcfc2f83e7dbdd/parsel-1.2.0-py2.py3-none-any.whl</div><div class="line">Collecting service-identity (from scrapy)</div><div class="line">  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/29/fa/995e364220979e577e7ca232440961db0bf996b6edaf586a7d1bd14d81f1/service_identity-17.0.0-py2.py3-none-any.whl</div><div class="line">Collecting six&gt;=1.5.2 (from scrapy)</div><div class="line">  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/c8/0a/b6723e1bc4c516cb687841499455a8505b44607ab535be01091c0f24f079/six-1.10.0-py2.py3-none-any.whl</div><div class="line">Collecting Twisted&gt;=13.1.0 (from scrapy)</div><div class="line">  Could not find a version that satisfies the requirement Twisted&gt;=13.1.0 (from scrapy) (from versions: )</div><div class="line">No matching distribution found for Twisted&gt;=13.1.0 (from scrapy)</div></pre></td></tr></table></figure></p>
<p>报错说找不到Twisted，尝试pip安装：<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">[root@mysql .pip]# pip install Twisted</div><div class="line">Collecting Twisted</div><div class="line">  Could not find a version that satisfies the requirement Twisted (from versions: )</div><div class="line">No matching distribution found for Twisted</div></pre></td></tr></table></figure></p>
<p>也找不到，只能单独下载Twisted并安装：<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">[root@mysql .pip]# wget https://twistedmatrix.com/Releases/Twisted/17.1/Twisted-17.1.0.tar.bz2</div><div class="line">[root@mysql .pip]# tar -jxvf Twisted-17.1.0.tar.bz2</div><div class="line">[root@mysql .pip]# cd Twisted-17.1.0</div><div class="line">[root@mysql Twisted-17.1.0]# python setup.py install</div></pre></td></tr></table></figure></p>
<p>然后再次安装scrapy即可：<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">[root@mysql Twisted-17.1.0]# pip install scrapy -i https://pypi.tuna.tsinghua.edu.cn/simple</div><div class="line">Collecting scrapy</div><div class="line">  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/a8/96/3affe11cf53a5d2105536919113d5b453479038bb486f7387f4ce4a3b83f/Scrapy-1.4.0-py2.py3-none-any.whl</div><div class="line">Collecting queuelib (from scrapy)</div><div class="line">  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/16/4f/b307fc978a21bfbb138e8e01a9f4953191d439e30578f5e4fd5befa77de1/queuelib-1.4.2-py2.py3-none-any.whl</div><div class="line">Collecting w3lib&gt;=1.17.0 (from scrapy)</div><div class="line">  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/20/3e/ba9865b88c39edd09100a8c8df11722c8881bbf76aef0c0ae5b970eb42b7/w3lib-1.17.0-py2.py3-none-any.whl</div><div class="line">Collecting cssselect&gt;=0.9 (from scrapy)</div><div class="line">  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/1d/e5/f1d410192e34b1034dba7804de5dbcdece20a883c445ad661e5ea8226b42/cssselect-1.0.1-py2.py3-none-any.whl</div><div class="line">Collecting lxml (from scrapy)</div><div class="line">  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/62/b7/aafdcf0c0ad0cf36a0835adde50f4a7e18241440b9897a88c80f520d0c76/lxml-3.8.0-cp27-cp27m-manylinux1_x86_64.whl</div><div class="line">Collecting parsel&gt;=1.1 (from scrapy)</div><div class="line">  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/d0/bd/c5c3cf9c490d328a1d1e5e942c3a2b84d6934d5666e9d4bcfc2f83e7dbdd/parsel-1.2.0-py2.py3-none-any.whl</div><div class="line">Collecting service-identity (from scrapy)</div><div class="line">  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/29/fa/995e364220979e577e7ca232440961db0bf996b6edaf586a7d1bd14d81f1/service_identity-17.0.0-py2.py3-none-any.whl</div><div class="line">Requirement already satisfied: six&gt;=1.5.2 in /usr/local/lib/python2.7/site-packages/six-1.10.0-py2.7.egg (from scrapy)</div><div class="line">Requirement already satisfied: Twisted&gt;=13.1.0 in /usr/local/lib/python2.7/site-packages/Twisted-17.1.0-py2.7-linux-x86_64.egg (from scrapy)</div><div class="line">Collecting PyDispatcher&gt;=2.0.5 (from scrapy)</div><div class="line">  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/cd/37/39aca520918ce1935bea9c356bcbb7ed7e52ad4e31bff9b943dfc8e7115b/PyDispatcher-2.0.5.tar.gz</div><div class="line">Collecting pyOpenSSL (from scrapy)</div><div class="line">  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/d0/39/7730559b75b565fd6983d857776fcb4982afb0e8faddb06170e59b62b41c/pyOpenSSL-17.1.0-py2.py3-none-any.whl (53kB)</div><div class="line">    100% |████████████████████████████████| 61kB 1.5MB/s </div><div class="line">Collecting pyasn1 (from service-identity-&gt;scrapy)</div><div class="line">  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/a5/ae/6b4c4cb9420edddd7401782f55504130d1269f2e5ae3ba3c986da167dd6c/pyasn1-0.2.3-py2.py3-none-any.whl (53kB)</div><div class="line">    100% |████████████████████████████████| 61kB 15.1MB/s </div><div class="line">Requirement already satisfied: attrs in /usr/local/lib/python2.7/site-packages/attrs-17.2.0-py2.7.egg (from service-identity-&gt;scrapy)</div><div class="line">Collecting pyasn1-modules (from service-identity-&gt;scrapy)</div><div class="line">  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/5b/a4/d4934b1b9d28541e37fa354a7dd3c3d45d19d92196df127e1342420a0ae6/pyasn1_modules-0.0.9-py2.py3-none-any.whl (60kB)</div><div class="line">    100% |████████████████████████████████| 61kB 7.0MB/s </div><div class="line">Requirement already satisfied: zope.interface&gt;=3.6.0 in /usr/local/lib/python2.7/site-packages/zope.interface-4.4.2-py2.7-linux-x86_64.egg (from Twisted&gt;=13.1.0-&gt;scrapy)</div><div class="line">Requirement already satisfied: constantly&gt;=15.1 in /usr/local/lib/python2.7/site-packages/constantly-15.1.0-py2.7.egg (from Twisted&gt;=13.1.0-&gt;scrapy)</div><div class="line">Requirement already satisfied: incremental&gt;=16.10.1 in ./.eggs/incremental-17.5.0-py2.7.egg (from Twisted&gt;=13.1.0-&gt;scrapy)</div><div class="line">Requirement already satisfied: Automat&gt;=0.3.0 in /usr/local/lib/python2.7/site-packages/Automat-0.6.0-py2.7.egg (from Twisted&gt;=13.1.0-&gt;scrapy)</div><div class="line">Collecting cryptography&gt;=1.9 (from pyOpenSSL-&gt;scrapy)</div><div class="line">  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/2a/0c/31bd69469e90035381f0197b48bf71032991d9f07a7e444c311b4a23a3df/cryptography-1.9.tar.gz (409kB)</div><div class="line">    100% |████████████████████████████████| 419kB 3.9MB/s </div><div class="line">Requirement already satisfied: setuptools in /usr/local/lib/python2.7/site-packages/setuptools-19.4-py2.7.egg (from zope.interface&gt;=3.6.0-&gt;Twisted&gt;=13.1.0-&gt;scrapy)</div><div class="line">Collecting idna&gt;=2.1 (from cryptography&gt;=1.9-&gt;pyOpenSSL-&gt;scrapy)</div><div class="line">  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/11/7d/9bbbd7bb35f34b0169542487d2a8859e44306bb2e6a4455d491800a5621f/idna-2.5-py2.py3-none-any.whl (55kB)</div><div class="line">    100% |████████████████████████████████| 61kB 10.2MB/s </div><div class="line">Collecting asn1crypto&gt;=0.21.0 (from cryptography&gt;=1.9-&gt;pyOpenSSL-&gt;scrapy)</div><div class="line">  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/97/ba/7e8117d8efcee589f4d96dd2b2eb1d997f96d27d214cf2b7134ad8acf6ab/asn1crypto-0.22.0-py2.py3-none-any.whl (97kB)</div><div class="line">    100% |████████████████████████████████| 102kB 13.8MB/s </div><div class="line">Collecting enum34 (from cryptography&gt;=1.9-&gt;pyOpenSSL-&gt;scrapy)</div><div class="line">  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/c5/db/e56e6b4bbac7c4a06de1c50de6fe1ef3810018ae11732a50f15f62c7d050/enum34-1.1.6-py2-none-any.whl</div><div class="line">Collecting ipaddress (from cryptography&gt;=1.9-&gt;pyOpenSSL-&gt;scrapy)</div><div class="line">  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/17/93/28f4dd560780dd70fe75ce7e2662869770dfac181f6bbb472179ea8da516/ipaddress-1.0.18-py2-none-any.whl</div><div class="line">Collecting cffi&gt;=1.7 (from cryptography&gt;=1.9-&gt;pyOpenSSL-&gt;scrapy)</div><div class="line">  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/90/aa/bae1c4627e3e3f631fb8e946da040f36931af86917f54e279ad6f4b29641/cffi-1.10.0-cp27-cp27m-manylinux1_x86_64.whl (394kB)</div><div class="line">    100% |████████████████████████████████| 399kB 3.0MB/s </div><div class="line">Collecting pycparser (from cffi&gt;=1.7-&gt;cryptography&gt;=1.9-&gt;pyOpenSSL-&gt;scrapy)</div><div class="line">  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/8c/2d/aad7f16146f4197a11f8e91fb81df177adcc2073d36a17b1491fd09df6ed/pycparser-2.18.tar.gz (245kB)</div><div class="line">    100% |████████████████████████████████| 256kB 6.4MB/s </div><div class="line">Installing collected packages: queuelib, w3lib, cssselect, lxml, parsel, idna, asn1crypto, enum34, ipaddress, pycparser, cffi, cryptography, pyOpenSSL, pyasn1, pyasn1-modules, service-identity, PyDispatcher, scrapy</div><div class="line">  Running setup.py install for pycparser ... done</div><div class="line">  Running setup.py install for cryptography ... done</div><div class="line">  Running setup.py install for PyDispatcher ... done</div><div class="line">Successfully installed PyDispatcher-2.0.5 asn1crypto-0.22.0 cffi-1.10.0 cryptography-1.9 cssselect-1.0.1 enum34-1.1.6 idna-2.5 ipaddress-1.0.18 lxml-3.8.0 parsel-1.2.0 pyOpenSSL-17.1.0 pyasn1-0.2.3 pyasn1-modules-0.0.9 pycparser-2.18 queuelib-1.4.2 scrapy-1.4.0 service-identity-17.0.0 w3lib-1.17.0</div></pre></td></tr></table></figure></p>
<h3 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h3><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">[root@mysql Twisted-17.1.0]# scrapy version</div><div class="line">Scrapy 1.4.0</div><div class="line">[root@mysql Twisted-17.1.0]# cd </div><div class="line">[root@mysql ~]# python </div><div class="line">Python 2.7.10 (default, Jan 18 2016, 17:00:09) </div><div class="line">[GCC 4.4.7 20120313 (Red Hat 4.4.7-11)] on linux2</div><div class="line">Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.</div><div class="line">&gt;&gt;&gt; import scrapy</div><div class="line">&gt;&gt;&gt; exit()</div><div class="line">[root@mysql ~]#</div></pre></td></tr></table></figure>
<h2 id="Windows10上安装Scrapy"><a href="#Windows10上安装Scrapy" class="headerlink" title="Windows10上安装Scrapy"></a>Windows10上安装Scrapy</h2><h3 id="安装步骤"><a href="#安装步骤" class="headerlink" title="安装步骤"></a>安装步骤</h3><p>windows上需要先下载openssl并将include目录拷贝到VC下。VC的具体路径因环境而不同，不过可以在安装报错日志中看到。经过各种报错后整理正确的安装步骤如下：<br>1）下载openssl：<a href="https://ci.cryptography.io/job/cryptography-support-jobs/job/openssl-release-1.1/" target="_blank" rel="external">https://ci.cryptography.io/job/cryptography-support-jobs/job/openssl-release-1.1/</a><br>如果python2.7是32位的就下载openssl-1.1.0f-2010-x86.zip，如果python是64位的就下载openssl-1.1.0f-2010-x86_64.zip，务必保证python和openssl操作系统位数一致。<br>2）将openssl-win32-2010\include下面的文件夹拷贝到C:\Users\Administrator\AppData\Local\Programs\Common\Microsoft\Visual C++ for Python\9.0\VC\include下。<br>3）将openssl-win32-2010\lib下面的文件拷贝到C:\Python27\libs下。<br>4）pip install scrapy -i <a href="https://pypi.tuna.tsinghua.edu.cn/simple" target="_blank" rel="external">https://pypi.tuna.tsinghua.edu.cn/simple</a></p>
<h3 id="遇到报错及解决"><a href="#遇到报错及解决" class="headerlink" title="遇到报错及解决"></a>遇到报错及解决</h3><p>报错1：<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">C:\Users\Administrator\AppData\Local\Programs\Common\Microsoft\Visual C++ for Py</div><div class="line">thon\9.0\VC\Bin\cl.exe /c /nologo /Ox /MD /W3 /GS- /DNDEBUG -IC:\Python27\includ</div><div class="line">e -IC:\Python27\PC /Tcbuild\temp.win32-2.7\Release\_openssl.c /Fobuild\temp.win3</div><div class="line">2-2.7\Release\build\temp.win32-2.7\Release\_openssl.obj</div><div class="line"></div><div class="line">_openssl.c</div><div class="line"></div><div class="line">build\temp.win32-2.7\Release\_openssl.c(434) : fatal error C1083: Cannot open in</div><div class="line">clude file: &apos;openssl/opensslv.h&apos;: No such file or directory</div><div class="line"></div><div class="line">error: command &apos;C:\\Users\\Administrator\\AppData\\Local\\Programs\\Common\\Micr</div><div class="line">osoft\\Visual C++ for Python\\9.0\\VC\\Bin\\cl.exe&apos; failed with exit status 2</div><div class="line"></div><div class="line">----------------------------------------</div><div class="line">Cleaning up...</div><div class="line">Command C:\Python27\python.exe -c &quot;import setuptools, tokenize;__file__=&apos;c:\\use</div><div class="line">rs\\admini~1\\appdata\\local\\temp\\pip_build_Administrator\\cryptography\\setup</div><div class="line">.py&apos;;exec(compile(getattr(tokenize, &apos;open&apos;, open)(__file__).read().replace(&apos;\r\n</div><div class="line">&apos;, &apos;\n&apos;), __file__, &apos;exec&apos;))&quot; install --record c:\users\admini~1\appdata\local\t</div><div class="line">emp\pip-7as3vx-record\install-record.txt --single-version-externally-managed --c</div><div class="line">ompile failed with error code 1 in c:\users\admini~1\appdata\local\temp\pip_buil</div><div class="line">d_Administrator\cryptography</div><div class="line">Storing debug log for failure in C:\Users\Administrator\pip\pip.log</div></pre></td></tr></table></figure></p>
<p>解决办法：下载openssl（如果python2.7是32位的就下载openssl-1.1.0f-2010-x86.zip，如果python是64位的就下载openssl-1.1.0f-2010-x86_64.zip）<br>下载网址：<a href="https://ci.cryptography.io/job/cryptography-support-jobs/job/openssl-release-1.1/" target="_blank" rel="external">https://ci.cryptography.io/job/cryptography-support-jobs/job/openssl-release-1.1/</a><br>下载后解压然后将openssl-win32-2010\include下面的文件夹拷贝到C:\Users\Administrator\AppData\Local\Programs\Common\Microsoft\Visual C++ for Python\9.0\VC\include<br>再次安装，遇到报错2。<br>报错2：<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">C:\Users\Administrator\AppData\Local\Programs\Common\Microsoft\Visual C++ for Python\9.0\VC\Bin\link.exe /DLL /nologo /INCREMENTAL:NO /LIBPATH:C:\Python27\libs /LIBPATH:C:\Python27\PCbuild libssl.lib libcrypto.lib advapi32.lib crypt32.lib gdi32.lib user32.lib ws2_32.lib /EXPORT:init_openssl build\temp.win32-2.7\Release\build\temp.win32-2.7\Release\_openssl.obj /OUT:build\lib.win32-2.7\cryptography\hazmat\bindings\_openssl.pyd /IMPLIB:build\temp.win32-2.7\Release\build\temp.win32-2.7\Release\_openssl.lib /MANIFESTFILE:build\temp.win32-2.7\Release\build\temp.win32-2.7\Release\_openssl.pyd.manifest /NXCOMPAT /DYNAMICBASE</div><div class="line">LINK : fatal error LNK1181: cannot open input file &apos;libssl.lib&apos;</div><div class="line">error: command &apos;C:\\Users\\Administrator\\AppData\\Local\\Programs\\Common\\Microsoft\\Visual C++ for Python\\9.0\\VC\\Bin\\link.exe&apos; failed with exit status 1181</div></pre></td></tr></table></figure></p>
<p>解决办法：将openssl-win32-2010\lib下面的文件拷贝到C:\Python27\libs，再次安装即可成功。<br>如果误将openssl-win64-2010\lib拷到C:\Python27\libs的话还会遇到下面的报错：<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">build\lib.win32-2.7\cryptography\hazmat\bindings\_openssl.pyd : fatal error LNK1120: 1037 unresolved externals</div><div class="line">error: command &apos;C:\\Users\\Administrator\\AppData\\Local\\Programs\\Common\\Microsoft\\Visual C++ for Python\\9.0\\VC\\Bin\\link.exe&apos; failed with exit status 1120</div></pre></td></tr></table></figure></p>
<p>所以务必保证python和openssl操作系统位数的一致。<br>报错3：<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">UnicodeDecodeError: &apos;ascii&apos; codec can&apos;t decode byte 0xb0 in position 1: ordinal not in range(128)</div></pre></td></tr></table></figure></p>
<p>解决办法：打开C:\Python27\Lib下的 mimetypes.py 文件，找到大概256行（你可以用Notepad++的搜索功能）的‘default_encoding = sys.getdefaultencoding()’。<br>在这行前面添加三行：<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">if sys.getdefaultencoding() != &apos;gbk&apos;:  </div><div class="line">    reload(sys)  </div><div class="line">    sys.setdefaultencoding(&apos;gbk&apos;)  </div><div class="line">default_encoding = sys.getdefaultencoding()</div></pre></td></tr></table></figure></p>
<h3 id="验证-1"><a href="#验证-1" class="headerlink" title="验证"></a>验证</h3><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">C:\&gt;python</div><div class="line">Python 2.7.9 (default, Dec 10 2014, 12:24:55) [MSC v.1500 32 bit (Intel)] on win</div><div class="line">32</div><div class="line">Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.</div><div class="line">&gt;&gt;&gt; import scrapy</div><div class="line">&gt;&gt;&gt; exit()</div><div class="line"></div><div class="line">C:\&gt;scrapy version</div><div class="line">Scrapy 1.4.0</div><div class="line"></div><div class="line">C:\&gt;scrapy bench</div><div class="line">2017-07-11 09:51:30 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: scrapybo</div><div class="line">t)</div><div class="line">2017-07-11 09:51:30 [scrapy.utils.log] INFO: Overridden settings: &#123;&apos;CLOSESPIDER_</div><div class="line">TIMEOUT&apos;: 10, &apos;LOG_LEVEL&apos;: &apos;INFO&apos;, &apos;LOGSTATS_INTERVAL&apos;: 1&#125;</div><div class="line">2017-07-11 09:51:32 [scrapy.middleware] INFO: Enabled extensions:</div><div class="line">[&apos;scrapy.extensions.closespider.CloseSpider&apos;,</div><div class="line"> &apos;scrapy.extensions.logstats.LogStats&apos;,</div><div class="line"> &apos;scrapy.extensions.telnet.TelnetConsole&apos;,</div><div class="line"> &apos;scrapy.extensions.corestats.CoreStats&apos;]</div><div class="line">2017-07-11 09:51:33 [scrapy.middleware] INFO: Enabled downloader middlewares:</div><div class="line">[&apos;scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware&apos;,</div><div class="line"> &apos;scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware&apos;,</div><div class="line"> &apos;scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware&apos;,</div><div class="line"> &apos;scrapy.downloadermiddlewares.useragent.UserAgentMiddleware&apos;,</div><div class="line"> &apos;scrapy.downloadermiddlewares.retry.RetryMiddleware&apos;,</div><div class="line"> &apos;scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware&apos;,</div><div class="line"> &apos;scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware&apos;,</div><div class="line"> &apos;scrapy.downloadermiddlewares.redirect.RedirectMiddleware&apos;,</div><div class="line"> &apos;scrapy.downloadermiddlewares.cookies.CookiesMiddleware&apos;,</div><div class="line"> &apos;scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware&apos;,</div><div class="line"> &apos;scrapy.downloadermiddlewares.stats.DownloaderStats&apos;]</div><div class="line">2017-07-11 09:51:33 [scrapy.middleware] INFO: Enabled spider middlewares:</div><div class="line">[&apos;scrapy.spidermiddlewares.httperror.HttpErrorMiddleware&apos;,</div><div class="line"> &apos;scrapy.spidermiddlewares.offsite.OffsiteMiddleware&apos;,</div><div class="line"> &apos;scrapy.spidermiddlewares.referer.RefererMiddleware&apos;,</div><div class="line"> &apos;scrapy.spidermiddlewares.urllength.UrlLengthMiddleware&apos;,</div><div class="line"> &apos;scrapy.spidermiddlewares.depth.DepthMiddleware&apos;]</div><div class="line">2017-07-11 09:51:33 [scrapy.middleware] INFO: Enabled item pipelines:</div><div class="line">[]</div><div class="line">2017-07-11 09:51:33 [scrapy.core.engine] INFO: Spider opened</div><div class="line">2017-07-11 09:51:33 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pag</div><div class="line">es/min), scraped 0 items (at 0 items/min)</div><div class="line">2017-07-11 09:51:34 [scrapy.extensions.logstats] INFO: Crawled 61 pages (at 3660</div><div class="line"> pages/min), scraped 0 items (at 0 items/min)</div><div class="line">2017-07-11 09:51:35 [scrapy.extensions.logstats] INFO: Crawled 133 pages (at 432</div><div class="line">0 pages/min), scraped 0 items (at 0 items/min)</div><div class="line">2017-07-11 09:51:36 [scrapy.extensions.logstats] INFO: Crawled 197 pages (at 384</div><div class="line">0 pages/min), scraped 0 items (at 0 items/min)</div><div class="line">2017-07-11 09:51:37 [scrapy.extensions.logstats] INFO: Crawled 262 pages (at 390</div><div class="line">0 pages/min), scraped 0 items (at 0 items/min)</div><div class="line">2017-07-11 09:51:38 [scrapy.extensions.logstats] INFO: Crawled 334 pages (at 432</div><div class="line">0 pages/min), scraped 0 items (at 0 items/min)</div><div class="line">2017-07-11 09:51:39 [scrapy.extensions.logstats] INFO: Crawled 405 pages (at 426</div><div class="line">0 pages/min), scraped 0 items (at 0 items/min)</div><div class="line">2017-07-11 09:51:40 [scrapy.extensions.logstats] INFO: Crawled 470 pages (at 390</div><div class="line">0 pages/min), scraped 0 items (at 0 items/min)</div><div class="line">2017-07-11 09:51:41 [scrapy.extensions.logstats] INFO: Crawled 533 pages (at 378</div><div class="line">0 pages/min), scraped 0 items (at 0 items/min)</div><div class="line">2017-07-11 09:51:42 [scrapy.extensions.logstats] INFO: Crawled 605 pages (at 432</div><div class="line">0 pages/min), scraped 0 items (at 0 items/min)</div><div class="line">2017-07-11 09:51:43 [scrapy.core.engine] INFO: Closing spider (closespider_timeo</div><div class="line">ut)</div><div class="line">2017-07-11 09:51:43 [scrapy.extensions.logstats] INFO: Crawled 670 pages (at 390</div><div class="line">0 pages/min), scraped 0 items (at 0 items/min)</div><div class="line">2017-07-11 09:51:44 [scrapy.statscollectors] INFO: Dumping Scrapy stats:</div><div class="line">&#123;&apos;downloader/request_bytes&apos;: 212136,</div><div class="line"> &apos;downloader/request_count&apos;: 686,</div><div class="line"> &apos;downloader/request_method_count/GET&apos;: 686,</div><div class="line"> &apos;downloader/response_bytes&apos;: 1017138,</div><div class="line"> &apos;downloader/response_count&apos;: 686,</div><div class="line"> &apos;downloader/response_status_count/200&apos;: 686,</div><div class="line"> &apos;dupefilter/filtered&apos;: 879,</div><div class="line"> &apos;finish_reason&apos;: &apos;closespider_timeout&apos;,</div><div class="line"> &apos;finish_time&apos;: datetime.datetime(2017, 7, 11, 1, 51, 44, 289000),</div><div class="line"> &apos;log_count/INFO&apos;: 17,</div><div class="line"> &apos;request_depth_max&apos;: 24,</div><div class="line"> &apos;response_received_count&apos;: 686,</div><div class="line"> &apos;scheduler/dequeued&apos;: 686,</div><div class="line"> &apos;scheduler/dequeued/memory&apos;: 686,</div><div class="line"> &apos;scheduler/enqueued&apos;: 12841,</div><div class="line"> &apos;scheduler/enqueued/memory&apos;: 12841,</div><div class="line"> &apos;start_time&apos;: datetime.datetime(2017, 7, 11, 1, 51, 33, 886000)&#125;</div><div class="line">2017-07-11 09:51:44 [scrapy.core.engine] INFO: Spider closed (closespider_timeou</div><div class="line">t)</div></pre></td></tr></table></figure>
<h3 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h3><p><a href="https://pypi.python.org/pypi/Scrapy" target="_blank" rel="external">https://pypi.python.org/pypi/Scrapy</a><br><a href="https://cryptography.io/en/latest/installation/#on-windows" target="_blank" rel="external">https://cryptography.io/en/latest/installation/#on-windows</a><br><a href="http://blog.csdn.net/zzk1995/article/details/51924510" target="_blank" rel="external">http://blog.csdn.net/zzk1995/article/details/51924510</a><br><a href="http://bbs.chinaunix.net/thread-4251968-1-1.html" target="_blank" rel="external">http://bbs.chinaunix.net/thread-4251968-1-1.html</a></p>
</the>
      
    </div>
    
  </div>
  
    
    <div class="copyright">
        <p><span>本文标题:</span><a href="/2017/07/11/scrapy-install/">Python爬虫框架scrapy的安装</a></p>
        <p><span>文章作者:</span><a href="/" title="回到主页">一条大河</a></p>
        <p><span>发布时间:</span>2017-07-11, 09:55:42</p>
        <p><span>最后更新:</span>2017-07-11, 10:40:00</p>
        <p>
            <span>原始链接:</span><a class="post-url" href="/2017/07/11/scrapy-install/" title="Python爬虫框架scrapy的安装">http://riverdba.github.io/2017/07/11/scrapy-install/</a>
            <span class="copy-path" data-clipboard-text="原文: http://riverdba.github.io/2017/07/11/scrapy-install/　　作者: 一条大河" title="点击复制文章链接"><i class="fa fa-clipboard"></i></span>
            <script> var clipboard = new Clipboard('.copy-path'); </script>
        </p>
        <p>
            <span>许可协议:</span><i class="fa fa-creative-commons"></i> <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" title="CC BY-NC-SA 4.0 International" target = "_blank">"署名-非商用-相同方式共享 4.0"</a> 转载请保留原文链接及作者。
        </p>
    </div>



    <nav id="article-nav">
        
            <div id="article-nav-newer" class="article-nav-title">
                <a href="/2017/07/13/mysql-transcation-uncommitted/">
                    mysql事务未提交引发的阻塞
                </a>
            </div>
        
        
            <div id="article-nav-older" class="article-nav-title">
                <a href="/2017/06/02/pt-kill/">
                    使用pt-kill实现MySQL的过载保护
                </a>
            </div>
        
    </nav>

  
</article>

    <div id="toc" class="toc-article">
        <strong class="toc-title">文章目录</strong>
        
            <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Linux上安装Scrapy"><span class="toc-number">1.</span> <span class="toc-text">Linux上安装Scrapy</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#安装"><span class="toc-number">1.1.</span> <span class="toc-text">安装</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#验证"><span class="toc-number">1.2.</span> <span class="toc-text">验证</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Windows10上安装Scrapy"><span class="toc-number">2.</span> <span class="toc-text">Windows10上安装Scrapy</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#安装步骤"><span class="toc-number">2.1.</span> <span class="toc-text">安装步骤</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#遇到报错及解决"><span class="toc-number">2.2.</span> <span class="toc-text">遇到报错及解决</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#验证-1"><span class="toc-number">2.3.</span> <span class="toc-text">验证</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#参考文档"><span class="toc-number">2.4.</span> <span class="toc-text">参考文档</span></a></li></ol></li></ol>
        
    </div>
    <style>
        .left-col .switch-btn,
        .left-col .switch-area {
            display: none;
        }
        .toc-level-6 i,
        .toc-level-6 ol {
            display: none !important;
        }
    </style>

    <input type="button" id="tocButton" value="隐藏目录"  title="点击按钮隐藏或者显示文章目录">

    <script>
        yiliaConfig.toc = ["隐藏目录", "显示目录", !!"false"];
    </script>



    
<div class="share">
    
        <div class="bdsharebuttonbox">
            <a href="#" class="fa fa-twitter bds_twi" data-cmd="twi" title="分享到推特"></a>
            <a href="#" class="fa fa-weibo bds_tsina" data-cmd="tsina" title="分享到新浪微博"></a>
            <a href="#" class="fa fa-qq bds_sqq" data-cmd="sqq" title="分享给 QQ 好友"></a>
            <a href="#" class="fa fa-files-o bds_copy" data-cmd="copy" title="复制网址"></a>
            <a href="#" class="fa fa fa-envelope-o bds_mail" data-cmd="mail" title="通过邮件分享"></a>
            <a href="#" class="fa fa-weixin bds_weixin" data-cmd="weixin" title="生成文章二维码"></a>
            <a href="#" class="fa fa-share-alt bds_more" data-cmd="more"></i></a>
        </div>
        <script>
            window._bd_share_config={
                "common":{"bdSnsKey":{},"bdText":"Python爬虫框架scrapy的安装　| Yangtze River's blog　","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"0","bdSize":"24"},"share":{}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];
        </script>
    

    
</div>







    
        <section id="comments">
    <style> aside.comment-bar { margin: auto 30px; }</style>
    <div id="disqus_thread"></div>
    <script>
        var disqus_config = function(){
            this.page.url = 'http://riverdba.github.io/2017/07/11/scrapy-install/';
            this.page.identifier = '2017/07/11/scrapy-install/';
        };
        var loadComment = function(){
            var d = document, s = d.createElement('script');
            s.src = '//https-riverdba-github-io.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        }
    </script>
    
    <script> loadComment(); </script>

</section>


    




    <div class="scroll" id="post-nav-button">
        
            <a href="/2017/07/13/mysql-transcation-uncommitted/" title="上一篇: mysql事务未提交引发的阻塞">
                <i class="fa fa-angle-left"></i>
            </a>
        

        <a title="文章列表"><i class="fa fa-bars"></i><i class="fa fa-times"></i></a>

        
            <a href="/2017/06/02/pt-kill/" title="下一篇: 使用pt-kill实现MySQL的过载保护">
                <i class="fa fa-angle-right"></i>
            </a>
        
    </div>

    <ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2019/04/25/mysql-query-optimization-case/">SQL优化案例</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/03/19/orchestrator/">MySQL高可用探索之orchestrator</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/03/18/strace-mysql/">使用strace跟踪mysql的运行</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/02/23/mysql-data-safety/">MySQL数据安全策略</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/02/22/mycat-consul-mgr/">探究MyCat+Consul+MGR高可用架构</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/11/14/mysql57-debug/">MySQL5.7之Debug模式</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/05/14/mysql-backup/">mysql备份失败</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/05/09/route-add/">linux路由添加和删除</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/11/17/The-DB-flashback-for-MyFlash/">MySQL闪回工具之MyFlash</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/08/29/sqlite3-install-for-python/">python2.7安装sqlite3模块</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/07/13/mysql-transcation-uncommitted/">mysql事务未提交引发的阻塞</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/07/11/scrapy-install/">Python爬虫框架scrapy的安装</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/06/02/pt-kill/">使用pt-kill实现MySQL的过载保护</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/05/25/mysql-binlog-filename/">mysql binlog文件扩展序号最大是多少</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/05/15/mysql-performance-schema/">mysql5.6之performance schema初探</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/05/04/gdb-debug-mysql/">使用GDB调试mysql源码</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/04/24/mycat-faq/">mycat常见问题集锦</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/04/24/select-on-mycat/">在mycat上使用select * 的影响</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/04/22/mycat-upgrade/">mycat1.4升级到1.5</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/04/21/mysql-sleep-process-too-many/">mysql sleep连接太多怎么办</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/04/20/online-ddl-tools-by-oak/">MySQL在线DDL工具之OAK</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/04/19/hive2mycat/">将hive输出文件导入mycat</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/04/15/archer-install/">archer安装及使用</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/04/13/inception-install/">Inception安装及使用</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/04/11/sysbench-for-mysql/">mysql基准测试</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/04/06/String-handling-of-mysql/">MySQL字符串处理一则</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/04/05/Non-SPJ-Optimization-of-mysql/">MySQL查询优化技术之非SPJ优化</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/04/01/MVCC-theory-study/">Innodb的MVCC实现原理</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/03/30/mysql-troubleshooting01/">update大量数据引发的故障</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/03/29/Deep-comprehend-mysql-replication/">深入理解mysql的主从复制</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/03/28/Sematic-Optimization-of-mysql/">mysql查询优化技术之语义优化</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/03/28/hexo-s-tips/">hexo's tips</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/03/27/hexo-s-comment/">实现hexo的评论功能</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/03/27/Performance-tuning-key-points-of-mysql/">mysql性能调优的关键点</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/03/22/join-elimination-technique-of-mysql/">mysql查询优化技术之连接消除</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/03/21/hello-world/">Hello World</a></li></ul>




    <script>
        
    </script>
</div>
      <footer id="footer">
    <div class="outer">
        <div id="footer-info">
            <div class="footer-left">
                <i class="fa fa-copyright"></i> 
                2017-2019 一条大河
            </div>
            <div class="footer-right">
                <a href="http://hexo.io/" target="_blank" title="快速、简洁且高效的博客框架">Hexo</a>  Theme <a href="https://github.com/MOxFIVE/hexo-theme-yelee" target="_blank" title="简而不减 Hexo 双栏博客主题  v3.5">Yelee</a> by MOxFIVE <i class="fa fa-heart animated infinite pulse"></i>
            </div>
        </div>
        
            <div class="visit">
                
                    <span id="busuanzi_container_site_pv" style='display:none'>
                        <span id="site-visit" title="本站到访数"><i class="fa fa-user" aria-hidden="true"></i><span id="busuanzi_value_site_uv"></span>
                        </span>
                    </span>
                
                
                    <span>| </span>
                
                
                    <span id="busuanzi_container_page_pv" style='display:none'>
                        <span id="page-visit"  title="本页阅读量"><i class="fa fa-eye animated infinite pulse" aria-hidden="true"></i><span id="busuanzi_value_page_pv"></span>
                        </span>
                    </span>
                
            </div>
        
    </div>
</footer>
    </div>
    
<script data-main="/js/main.js" src="//cdn.bootcss.com/require.js/2.2.0/require.min.js"></script>

    <script>
        $(document).ready(function() {
            var iPad = window.navigator.userAgent.indexOf('iPad');
            if (iPad > -1 || $(".left-col").css("display") === "none") {
                var bgColorList = ["#9db3f4", "#414141", "#e5a859", "#f5dfc6", "#c084a0", "#847e72", "#cd8390", "#996731"];
                var bgColor = Math.ceil(Math.random() * (bgColorList.length - 1));
                $("body").css({"background-color": bgColorList[bgColor], "background-size": "cover"});
            }
            else {
                var backgroundnum = 5;
                var backgroundimg = "url(/background/bg-x.jpg)".replace(/x/gi, Math.ceil(Math.random() * backgroundnum));
                $("body").css({"background": backgroundimg, "background-attachment": "fixed", "background-size": "cover"});
            }
        })
    </script>





<div class="scroll" id="scroll">
    <a href="#" title="返回顶部"><i class="fa fa-arrow-up"></i></a>
    <a href="#comments" onclick="load$hide();" title="查看评论"><i class="fa fa-comments-o"></i></a>
    <a href="#footer" title="转到底部"><i class="fa fa-arrow-down"></i></a>
</div>
<script>
    // Open in New Window
    
        var oOpenInNew = {
            
            
            
            
            
            
             archives: ".archive-article-title", 
             miniArchives: "a.post-list-link", 
            
             friends: "#js-friends a", 
             socail: ".social a" 
        }
        for (var x in oOpenInNew) {
            $(oOpenInNew[x]).attr("target", "_blank");
        }
    
</script>

<script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>
  </div>
</body>
</html>